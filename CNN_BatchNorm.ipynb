{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEL0LqOvNctE"
      },
      "source": [
        "# In this tutorial we will build basic CNN for image classification.\n",
        "Author :- Ankur Mali\n",
        "* We will define our model and learn how to use keras module to build custom layers\n",
        "* We will also design our own training loop, that is identical to model.fit in Keras.\n",
        "* The aim of this excercise is to teach, how to use exisiting Tensorflow API to construct our own module and integrate it with tf.keras API."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SK3DMbzThNBc"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(1234)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3wnZ5tvOTCV"
      },
      "source": [
        "#Things to do\n",
        "* Remember to Normalize your data and create validation split from train set.\n",
        "* Learn about tf.data, tf.slices and also tf.records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWo3ho3whTWU",
        "outputId": "335398b0-8a00-499d-82da-539843e9e4e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 1s 0us/step\n",
            "26435584/26421880 [==============================] - 1s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n",
            "(50000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n",
            "(10000, 28, 28, 1)\n",
            "391\n",
            "79\n"
          ]
        }
      ],
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
        "x_val = x_train[50000:60000]\n",
        "x_train = x_train[0:50000]\n",
        "y_val = y_train[50000:60000]\n",
        "y_train = y_train[0:50000]\n",
        "x_train = x_train.astype(np.float32).reshape(-1,28,28,1) / 255.0\n",
        "x_val = x_val.astype(np.float32).reshape(-1,28,28,1) / 255.0\n",
        "x_test = x_test.astype(np.float32).reshape(-1,28,28,1) / 255.0\n",
        "y_train = tf.one_hot(y_train, depth=10)\n",
        "y_val = tf.one_hot(y_val, depth=10)\n",
        "y_test = tf.one_hot(y_test, depth=10)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "print(x_val.shape)\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(128)\n",
        "train_dataset_full = train_dataset.shuffle(buffer_size=1024).batch(len(train_dataset))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
        "val_dataset = val_dataset.batch(128)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_dataset = test_dataset.batch(128)\n",
        "print(len(train_dataset))\n",
        "print(len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIjh52BataYG"
      },
      "outputs": [],
      "source": [
        "class BatchNorm(tf.keras.layers.Layer):\n",
        "    def __init__(self, dim, epsilon=10e-8, momentum=0.99):\n",
        "        super(BatchNorm, self).__init__()\n",
        "\n",
        "        self.epsilon = epsilon\n",
        "        self.momentum = momentum\n",
        "        self.dim = dim\n",
        "\n",
        "        self.it_call = 0\n",
        "        self.batch_size = 0\n",
        "\n",
        "        self.mu = self.add_weight(\"mu\", shape=[self.dim,], \n",
        "                                initializer=\"zeros\",\n",
        "                                trainable=False)\n",
        "        self.var = self.add_weight(\"var\", shape=[self.dim,], \n",
        "                                   initializer=\"zeros\",\n",
        "                                   trainable=False)\n",
        "\n",
        "        self.gamma = self.add_weight(\"gamma\", shape=[1, self.dim],\n",
        "                                     initializer=\"random_normal\",\n",
        "                                     trainable=True)\n",
        "        self.beta = self.add_weight(\"beta\", shape=[1, self.dim],\n",
        "                                    initializer=\"random_normal\",\n",
        "                                    trainable=True)\n",
        "        \n",
        "    \n",
        "    def call(self, inputs, is_training):\n",
        "        \"\"\"forward\n",
        "        BN(x) = gamma * ((x - mu) / sqrt(var + epsilon)) + beta\n",
        "        \"\"\"\n",
        "\n",
        "        self.it_call += 1\n",
        "\n",
        "        if is_training:   # is_training == True: compute BN \n",
        "            if self.batch_size == 0:\n",
        "                self.batch_size = inputs.shape[0]\n",
        "            \n",
        "            batch_mu = tf.math.reduce_mean(inputs, axis=(0,1,2))\n",
        "            batch_var = tf.math.reduce_variance(inputs, axis=(0,1,2))\n",
        "            \n",
        "            normalized_inputs = tf.math.divide((inputs - batch_mu), tf.math.sqrt(batch_var + self.epsilon))\n",
        "            bn_inputs = tf.math.multiply(self.gamma, normalized_inputs) + self.beta\n",
        "\n",
        "            # update mu and var\n",
        "            if inputs.shape[0] == self.batch_size:\n",
        "                running_mu = batch_mu\n",
        "                running_var = batch_var\n",
        "            else:\n",
        "                # the last batch in training may have sample less than batch size\n",
        "                running_mu = batch_mu / inputs.shape[0] * self.batch_size\n",
        "                running_var = batch_var / inputs.shape[0] * self.batch_size\n",
        "            \n",
        "            cur_mu = running_mu * (self.momentum / self.it_call) + self.mu * (1 - (self.momentum/self.it_call))\n",
        "            self.mu.assign(cur_mu)\n",
        "            cur_var = running_var * (self.momentum / self.it_call) + self.var * (1 - (self.momentum/self.it_call))\n",
        "            self.var.assign(cur_var)\n",
        "\n",
        "\n",
        "        else: # is_training == False\n",
        "            normalized_inputs = tf.math.divide((inputs - self.mu), tf.math.sqrt(self.var + self.epsilon))\n",
        "            bn_inputs = tf.math.multiply(self.gamma, normalized_inputs) + self.beta\n",
        "        \n",
        "        return bn_inputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rs9r9QDvO48Y"
      },
      "source": [
        "# Create your custom CNN class\n",
        "* Convolution layers has 4D weights of size (h,w,input_feature, output_feature), where h=height of your kernel and w = width of our kernel. If you add batches then it is 5D.\n",
        "* Now your model will convolve across your input feature map with kernel and create output feature map, that is then passed to next layer.\n",
        "* As we have learned in our prior class, to initialize your weights, we use tf.Variable(weight_init(size)), tf.keras.layers.Conv2D will do this for you. Play with the function and see how it works for your problem.\n",
        "* Few important concepts, learn to save your model after every k epochs and start re-training from last checkpoint. This is very useful, and you don't need to retrain your model from scratch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRXM6_Bpq_Wz"
      },
      "source": [
        "##Batch Norm Before RELU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGjSk_lMhb7V"
      },
      "outputs": [],
      "source": [
        "class ImageRecognitionCNN(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, num_classes, device='cpu:0', checkpoint_directory=None):\n",
        "        ''' Define the parameterized layers used during forward-pass, the device\n",
        "            where you would like to run the computation (GPU, TPU, CPU) on and the checkpoint\n",
        "            directory.\n",
        "            \n",
        "            Args:\n",
        "                num_classes: the number of labels in the network.\n",
        "                device: string, 'cpu:n' or 'gpu:n' (n can vary). Default, 'cpu:0'.\n",
        "                checkpoint_directory: the directory where you would like to save or \n",
        "                                      restore a model.\n",
        "        ''' \n",
        "        super(ImageRecognitionCNN, self).__init__()\n",
        "        \n",
        "        # Initialize layers\n",
        "        self.conv1 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\n",
        "        self.conv2 = tf.keras.layers.Conv2D(64, 3,padding='same', activation=None)\n",
        "        self.pool1 = tf.keras.layers.MaxPool2D()\n",
        "        self.conv3 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\n",
        "        self.conv4 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\n",
        "        # self.pool2 = tf.keras.layers.MaxPool2D()\n",
        "        # self.conv5 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\n",
        "        # self.pool2 = tf.keras.layers.MaxPool2D()\n",
        "        # self.conv6 = tf.keras.layers.Conv2D(64, 3, 2, padding='same', activation=None)\n",
        "        # self.conv7 = tf.keras.layers.Conv2D(64, 1, padding='same', activation=None)\n",
        "        self.conv8 = tf.keras.layers.Conv2D(num_classes, 1, padding='same', activation=None)\n",
        "        self.BatchNorm=BatchNorm(64)\n",
        "        \n",
        "        # Define the device \n",
        "        self.device = device\n",
        "        \n",
        "        # Define the checkpoint directory\n",
        "        self.checkpoint_directory = checkpoint_directory\n",
        "        self.acc = tf.keras.metrics.Accuracy()\n",
        "\n",
        "\n",
        "    def predict(self, images, training=True): #by default training is true\n",
        "        \"\"\" Predicts the probability of each class, based on the input sample.\n",
        "            \n",
        "            Args:\n",
        "                images: 4D tensor. Either an image or a batch of images.\n",
        "                training: Boolean. Either the network is predicting in\n",
        "                          training mode or not.\n",
        "                         \n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        \n",
        "        x = self.conv1(images) # (128, 28, 28, 1)(batch,28,28,1) ->(128, 28, 28, 64)<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
        "        x=self.BatchNorm(x,training)\n",
        "\n",
        "        # print(x.shape)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        # print(x.shape)\n",
        "        # BatchNorm()(x)\n",
        "\n",
        "        x=self.BatchNorm(x,training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv3(x)\n",
        "        # BatchNorm()(x)\n",
        "\n",
        "\n",
        "        x=self.BatchNorm(x,training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv4(x)\n",
        "\n",
        "        # BatchNorm()(x)\n",
        "        x=self.BatchNorm(x,training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv8(x)\n",
        "        #x = tf.nn.relu(x)\n",
        "        #print(x.shape)\n",
        "        x = tf.reshape(x, (-1, 1, 10))\n",
        "        #x = tf.keras.layers.Flatten(x)\n",
        "        return x\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    def loss_fn(self, images, target, training):\n",
        "        \"\"\" Defines the loss function used during \n",
        "            training.         \n",
        "        \"\"\"\n",
        "        preds = self.predict(images, training)\n",
        "        #print(preds.shape)\n",
        "        #print(target.shape)\n",
        "        loss = tf.nn.softmax_cross_entropy_with_logits(labels=target, logits=preds)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def grads_fn(self, images, target, training):\n",
        "        \"\"\" Dynamically computes the gradients of the loss value\n",
        "            with respect to the parameters of the model, in each\n",
        "            forward pass.\n",
        "        \"\"\"\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = self.loss_fn(images, target, training)\n",
        "        return tape.gradient(loss, self.variables)\n",
        "    \n",
        "    def restore_model(self):\n",
        "        \"\"\" Function to restore trained model.\n",
        "        \"\"\"\n",
        "        with tf.device(self.device):\n",
        "            # Run the model once to initialize variables\n",
        "            dummy_input = tf.constant(tf.zeros((1,48,48,1)))\n",
        "            dummy_pred = self.predict(dummy_input, training=training) #False\n",
        "            # Restore the variables of the model\n",
        "            saver = tf.Saver(self.variables)\n",
        "            saver.restore(tf.train.latest_checkpoint\n",
        "                          (self.checkpoint_directory))\n",
        "    \n",
        "    def save_model(self, global_step=0):\n",
        "        \"\"\" Function to save trained model.\n",
        "        \"\"\"\n",
        "        tf.Saver(self.variables).save(self.checkpoint_directory, \n",
        "                                       global_step=global_step)   \n",
        "    \n",
        "\n",
        "    def compute_accuracy_2(self, images, targets):\n",
        "        \"\"\" Compute the accuracy on the input data.\n",
        "        \"\"\"\n",
        "        with tf.device(self.device):\n",
        "            \n",
        "            # Predict the probability of each class\n",
        "            logits = self.predict(images, training=training)#False\n",
        "            # Select the class with the highest probability\n",
        "            \n",
        "            logits = tf.nn.softmax(logits)\n",
        "            logits = tf.reshape(logits, [-1, 10])\n",
        "            targets = tf.reshape(targets, [-1,10])\n",
        "            preds = tf.argmax(logits, axis=1)\n",
        "            goal = tf.argmax(targets, axis=1)\n",
        "            self.acc.update_state(goal, preds)\n",
        "            # Compute the accuracy\n",
        "            result = self.acc.result().numpy()\n",
        "        return result\n",
        "\n",
        "  \n",
        "    def fit_fc(self, training_data, eval_data, optimizer, num_epochs=500, \n",
        "            early_stopping_rounds=10, verbose=10, train_from_scratch=False):\n",
        "        \"\"\" Function to train the model, using the selected optimizer and\n",
        "            for the desired number of epochs. You can either train from scratch\n",
        "            or load the latest model trained. Early stopping is used in order to\n",
        "            mitigate the risk of overfitting the network.\n",
        "            \n",
        "            Args:\n",
        "                training_data: the data you would like to train the model on.\n",
        "                                Must be in the tf.data.Dataset format.\n",
        "                eval_data: the data you would like to evaluate the model on.\n",
        "                            Must be in the tf.data.Dataset format.\n",
        "                optimizer: the optimizer used during training.\n",
        "                num_epochs: the maximum number of iterations you would like to \n",
        "                            train the model.\n",
        "                early_stopping_rounds: stop training if the loss on the eval \n",
        "                                       dataset does not decrease after n epochs.\n",
        "                verbose: int. Specify how often to print the loss value of the network.\n",
        "                train_from_scratch: boolean. Whether to initialize variables of the\n",
        "                                    the last trained model or initialize them\n",
        "                                    randomly.\n",
        "        \"\"\" \n",
        "    \n",
        "        if train_from_scratch==False:\n",
        "            self.restore_model()\n",
        "        \n",
        "        # Initialize best loss. This variable will store the lowest loss on the\n",
        "        # eval dataset.\n",
        "        best_loss = 999\n",
        "        \n",
        "        # Initialize classes to update the mean loss of train and eval\n",
        "        train_loss = tf.keras.metrics.Mean('train_loss')\n",
        "        eval_loss = tf.keras.metrics.Mean('eval_loss')\n",
        "        acc_train = tf.keras.metrics.Mean('train_acc')\n",
        "        acc_val = tf.keras.metrics.Mean('val_acc')\n",
        "        \n",
        "        # Initialize dictionary to store the loss history\n",
        "        self.history = {}\n",
        "        self.history['train_loss'] = []\n",
        "        self.history['eval_loss'] = []\n",
        "        self.history['train_acc'] = []\n",
        "        self.history['val_acc'] = []\n",
        "        \n",
        "        # Begin training\n",
        "        \n",
        "        with tf.device(self.device):\n",
        "            for i in range(num_epochs):\n",
        "                # Training with gradient descent\n",
        "                #training_data_x = training_data.shuffle(buffer_size=1024).batch(128)\n",
        "                for step, (images, target) in enumerate(training_data):\n",
        "                    grads = self.grads_fn(images, target, training=training)#True\n",
        "                    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "                    \n",
        "                # Compute the loss on the training data after one epoch\n",
        "                for step, (images, target) in enumerate(training_data):\n",
        "                    loss = self.loss_fn(images, target, training=training) #False\n",
        "                    accuracy = self.compute_accuracy_2(images,target)\n",
        "                    acc_train(accuracy)\n",
        "                    train_loss(loss)\n",
        "                self.history['train_loss'].append(train_loss.result().numpy())\n",
        "                self.history['train_acc'].append(acc_train.result().numpy())\n",
        "                # Reset metrics\n",
        "                train_loss.reset_states()\n",
        "                acc_train.reset_states()\n",
        "                \n",
        "                # Compute the loss on the eval data after one epoch\n",
        "                for step, (images, target) in enumerate(eval_data):\n",
        "                    loss = self.loss_fn(images, target, training=training) #False\n",
        "                    accuracy = self.compute_accuracy_2(images,target)\n",
        "                    acc_val(accuracy)\n",
        "                    eval_loss(loss)\n",
        "                self.history['eval_loss'].append(eval_loss.result().numpy())\n",
        "                self.history['val_acc'].append(acc_val.result().numpy())\n",
        "                # Reset metrics\n",
        "                eval_loss.reset_states()\n",
        "                acc_val.reset_states()\n",
        "                \n",
        "                # Print train and eval losses\n",
        "                if (i==0) | ((i+1)%verbose==0):\n",
        "                    print('Train loss at epoch %d: ' %(i+1), self.history['train_loss'][-1])\n",
        "                    print('Train Acc at epoch %d: ' %(i+1), self.history['train_acc'][-1])\n",
        "                    \n",
        "                    print('Eval loss at epoch %d: ' %(i+1), self.history['eval_loss'][-1])\n",
        "                    print('Eval Acc at epoch %d: ' %(i+1), self.history['val_acc'][-1])\n",
        "\n",
        "                # Check for early stopping\n",
        "                if self.history['eval_loss'][-1]<best_loss:\n",
        "                    best_loss = self.history['eval_loss'][-1]\n",
        "                    count = early_stopping_rounds\n",
        "                else:\n",
        "                    count -= 1\n",
        "                if count==0:\n",
        "                    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4a-iuiHIypry"
      },
      "outputs": [],
      "source": [
        "# Specify the path where you want to save/restore the trained variables.\n",
        "checkpoint_directory = '/content/sample_data/model_checkpoint'\n",
        "\n",
        "# Use the GPU if available.\n",
        "device = 'gpu:0'\n",
        "\n",
        "# Define optimizer.\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=1e-4)\n",
        "\n",
        "# Instantiate model. This doesn't initialize the variables yet.\n",
        "model = ImageRecognitionCNN(num_classes=10, device=device, \n",
        "                              checkpoint_directory=checkpoint_directory)\n",
        "\n",
        "#model = ImageRecognitionCNN(num_classes=7, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8uHLAyoeJTx",
        "outputId": "49295090-01bd-4458-d9cb-63fd01f5a5c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial on random seed: 31\n",
            "Train loss at epoch 1:  1.0975136\n",
            "Train Acc at epoch 1:  0.7989086\n",
            "Eval loss at epoch 1:  1.1030124\n",
            "Eval Acc at epoch 1:  0.80048335\n",
            "Train loss at epoch 2:  0.64961463\n",
            "Train Acc at epoch 2:  0.8134409\n",
            "Eval loss at epoch 2:  0.65992224\n",
            "Eval Acc at epoch 2:  0.8230334\n",
            "Train loss at epoch 3:  0.46760276\n",
            "Train Acc at epoch 3:  0.8320499\n",
            "Eval loss at epoch 3:  0.48292813\n",
            "Eval Acc at epoch 3:  0.8396141\n",
            "Train loss at epoch 4:  0.37645957\n",
            "Train Acc at epoch 4:  0.84604394\n",
            "Eval loss at epoch 4:  0.3948908\n",
            "Eval Acc at epoch 4:  0.8517073\n",
            "Train loss at epoch 5:  0.32155225\n",
            "Train Acc at epoch 5:  0.8568461\n",
            "Eval loss at epoch 5:  0.3445224\n",
            "Eval Acc at epoch 5:  0.86143214\n",
            "Train loss at epoch 6:  0.28820294\n",
            "Train Acc at epoch 6:  0.86543995\n",
            "Eval loss at epoch 6:  0.31507784\n",
            "Eval Acc at epoch 6:  0.8692554\n",
            "Train loss at epoch 7:  0.26136118\n",
            "Train Acc at epoch 7:  0.8725977\n",
            "Eval loss at epoch 7:  0.29113007\n",
            "Eval Acc at epoch 7:  0.87575316\n",
            "Train loss at epoch 8:  0.24640325\n",
            "Train Acc at epoch 8:  0.87851197\n",
            "Eval loss at epoch 8:  0.2826157\n",
            "Eval Acc at epoch 8:  0.88113356\n",
            "Train loss at epoch 9:  0.22558156\n",
            "Train Acc at epoch 9:  0.8835671\n",
            "Eval loss at epoch 9:  0.26620802\n",
            "Eval Acc at epoch 9:  0.88591254\n",
            "Train loss at epoch 10:  0.21737598\n",
            "Train Acc at epoch 10:  0.887972\n",
            "Eval loss at epoch 10:  0.26436967\n",
            "Eval Acc at epoch 10:  0.8899555\n",
            "Train loss at epoch 11:  0.2011811\n",
            "Train Acc at epoch 11:  0.89184093\n",
            "Eval loss at epoch 11:  0.25204152\n",
            "Eval Acc at epoch 11:  0.89367896\n",
            "Train loss at epoch 12:  0.1889796\n",
            "Train Acc at epoch 12:  0.8953706\n",
            "Eval loss at epoch 12:  0.24596307\n",
            "Eval Acc at epoch 12:  0.8970816\n",
            "Train loss at epoch 13:  0.17974654\n",
            "Train Acc at epoch 13:  0.89863753\n",
            "Eval loss at epoch 13:  0.24246602\n",
            "Eval Acc at epoch 13:  0.9001906\n",
            "Train loss at epoch 14:  0.17371096\n",
            "Train Acc at epoch 14:  0.9015783\n",
            "Eval loss at epoch 14:  0.24240737\n",
            "Eval Acc at epoch 14:  0.9029916\n",
            "Train loss at epoch 15:  0.1664491\n",
            "Train Acc at epoch 15:  0.9042648\n",
            "Eval loss at epoch 15:  0.2395217\n",
            "Eval Acc at epoch 15:  0.90552986\n",
            "Train loss at epoch 16:  0.15361485\n",
            "Train Acc at epoch 16:  0.9067475\n",
            "Eval loss at epoch 16:  0.23225622\n",
            "Eval Acc at epoch 16:  0.90800166\n",
            "Train loss at epoch 17:  0.149355\n",
            "Train Acc at epoch 17:  0.90912014\n",
            "Eval loss at epoch 17:  0.23471306\n",
            "Eval Acc at epoch 17:  0.9102645\n",
            "Train loss at epoch 18:  0.1461469\n",
            "Train Acc at epoch 18:  0.9112851\n",
            "Eval loss at epoch 18:  0.23844692\n",
            "Eval Acc at epoch 18:  0.91232723\n",
            "Trial on random seed: 24\n",
            "Train loss at epoch 1:  0.56894225\n",
            "Train Acc at epoch 1:  0.85553324\n",
            "Eval loss at epoch 1:  0.57903534\n",
            "Eval Acc at epoch 1:  0.8562124\n",
            "Train loss at epoch 2:  0.38105673\n",
            "Train Acc at epoch 2:  0.8644229\n",
            "Eval loss at epoch 2:  0.39694542\n",
            "Eval Acc at epoch 2:  0.87114996\n",
            "Train loss at epoch 3:  0.31378528\n",
            "Train Acc at epoch 3:  0.8765678\n",
            "Eval loss at epoch 3:  0.3366729\n",
            "Eval Acc at epoch 3:  0.88119084\n",
            "Train loss at epoch 4:  0.27298743\n",
            "Train Acc at epoch 4:  0.8851658\n",
            "Eval loss at epoch 4:  0.30042437\n",
            "Eval Acc at epoch 4:  0.8887216\n",
            "Train loss at epoch 5:  0.25118202\n",
            "Train Acc at epoch 5:  0.89157265\n",
            "Eval loss at epoch 5:  0.2845446\n",
            "Eval Acc at epoch 5:  0.8942338\n",
            "Train loss at epoch 6:  0.22975144\n",
            "Train Acc at epoch 6:  0.8966001\n",
            "Eval loss at epoch 6:  0.267557\n",
            "Eval Acc at epoch 6:  0.89894116\n",
            "Train loss at epoch 7:  0.22071947\n",
            "Train Acc at epoch 7:  0.90082586\n",
            "Eval loss at epoch 7:  0.26363176\n",
            "Eval Acc at epoch 7:  0.9027057\n",
            "Train loss at epoch 8:  0.20651853\n",
            "Train Acc at epoch 8:  0.90434253\n",
            "Eval loss at epoch 8:  0.25494093\n",
            "Eval Acc at epoch 8:  0.9059793\n",
            "Train loss at epoch 9:  0.19257675\n",
            "Train Acc at epoch 9:  0.9074273\n",
            "Eval loss at epoch 9:  0.24670015\n",
            "Eval Acc at epoch 9:  0.9088884\n",
            "Train loss at epoch 10:  0.18341585\n",
            "Train Acc at epoch 10:  0.91018456\n",
            "Eval loss at epoch 10:  0.24363223\n",
            "Eval Acc at epoch 10:  0.91150326\n",
            "Train loss at epoch 11:  0.17242324\n",
            "Train Acc at epoch 11:  0.9127502\n",
            "Eval loss at epoch 11:  0.238601\n",
            "Eval Acc at epoch 11:  0.91404194\n",
            "Train loss at epoch 12:  0.16843945\n",
            "Train Acc at epoch 12:  0.91511834\n",
            "Eval loss at epoch 12:  0.24051021\n",
            "Eval Acc at epoch 12:  0.9162475\n",
            "Train loss at epoch 13:  0.15164357\n",
            "Train Acc at epoch 13:  0.9173499\n",
            "Eval loss at epoch 13:  0.23081501\n",
            "Eval Acc at epoch 13:  0.9185\n",
            "Train loss at epoch 14:  0.1481972\n",
            "Train Acc at epoch 14:  0.9195004\n",
            "Eval loss at epoch 14:  0.23330022\n",
            "Eval Acc at epoch 14:  0.9205607\n",
            "Train loss at epoch 15:  0.13900973\n",
            "Train Acc at epoch 15:  0.92152596\n",
            "Eval loss at epoch 15:  0.22972903\n",
            "Eval Acc at epoch 15:  0.9225404\n",
            "Train loss at epoch 16:  0.1338738\n",
            "Train Acc at epoch 16:  0.9234223\n",
            "Eval loss at epoch 16:  0.22999768\n",
            "Eval Acc at epoch 16:  0.924341\n",
            "Train loss at epoch 17:  0.12470017\n",
            "Train Acc at epoch 17:  0.9252131\n",
            "Eval loss at epoch 17:  0.22695276\n",
            "Eval Acc at epoch 17:  0.9261128\n",
            "Train loss at epoch 18:  0.11737918\n",
            "Train Acc at epoch 18:  0.9269836\n",
            "Eval loss at epoch 18:  0.2256439\n",
            "Eval Acc at epoch 18:  0.92786163\n",
            "Train loss at epoch 19:  0.11430732\n",
            "Train Acc at epoch 19:  0.9286267\n",
            "Eval loss at epoch 19:  0.22809407\n",
            "Eval Acc at epoch 19:  0.92940784\n",
            "Train loss at epoch 20:  0.10834975\n",
            "Train Acc at epoch 20:  0.93013686\n",
            "Eval loss at epoch 20:  0.22987989\n",
            "Eval Acc at epoch 20:  0.9309213\n",
            "Trial on random seed: 36\n",
            "Train loss at epoch 1:  0.5580434\n",
            "Train Acc at epoch 1:  0.85166055\n",
            "Eval loss at epoch 1:  0.569273\n",
            "Eval Acc at epoch 1:  0.8531477\n",
            "Train loss at epoch 2:  0.37671632\n",
            "Train Acc at epoch 2:  0.86253166\n",
            "Eval loss at epoch 2:  0.39412108\n",
            "Eval Acc at epoch 2:  0.87005633\n",
            "Train loss at epoch 3:  0.31562978\n",
            "Train Acc at epoch 3:  0.8749009\n",
            "Eval loss at epoch 3:  0.33874777\n",
            "Eval Acc at epoch 3:  0.8791266\n",
            "Train loss at epoch 4:  0.27595493\n",
            "Train Acc at epoch 4:  0.8828477\n",
            "Eval loss at epoch 4:  0.30493817\n",
            "Eval Acc at epoch 4:  0.88626456\n",
            "Train loss at epoch 5:  0.24959223\n",
            "Train Acc at epoch 5:  0.8892905\n",
            "Eval loss at epoch 5:  0.28347254\n",
            "Eval Acc at epoch 5:  0.8922208\n",
            "Train loss at epoch 6:  0.23107965\n",
            "Train Acc at epoch 6:  0.89473736\n",
            "Eval loss at epoch 6:  0.2706806\n",
            "Eval Acc at epoch 6:  0.8970849\n",
            "Train loss at epoch 7:  0.21320672\n",
            "Train Acc at epoch 7:  0.8991917\n",
            "Eval loss at epoch 7:  0.25783828\n",
            "Eval Acc at epoch 7:  0.90131843\n",
            "Train loss at epoch 8:  0.1972486\n",
            "Train Acc at epoch 8:  0.90318966\n",
            "Eval loss at epoch 8:  0.2469771\n",
            "Eval Acc at epoch 8:  0.9051202\n",
            "Train loss at epoch 9:  0.18998395\n",
            "Train Acc at epoch 9:  0.9067119\n",
            "Eval loss at epoch 9:  0.24546672\n",
            "Eval Acc at epoch 9:  0.9082905\n",
            "Train loss at epoch 10:  0.18718667\n",
            "Train Acc at epoch 10:  0.909577\n",
            "Eval loss at epoch 10:  0.24970928\n",
            "Eval Acc at epoch 10:  0.9108281\n",
            "Train loss at epoch 11:  0.1731524\n",
            "Train Acc at epoch 11:  0.91203827\n",
            "Eval loss at epoch 11:  0.24228723\n",
            "Eval Acc at epoch 11:  0.9132709\n",
            "Train loss at epoch 12:  0.15907562\n",
            "Train Acc at epoch 12:  0.9144928\n",
            "Eval loss at epoch 12:  0.23407796\n",
            "Eval Acc at epoch 12:  0.91576385\n",
            "Train loss at epoch 13:  0.15302931\n",
            "Train Acc at epoch 13:  0.91689366\n",
            "Eval loss at epoch 13:  0.23230581\n",
            "Eval Acc at epoch 13:  0.9180189\n",
            "Train loss at epoch 14:  0.1439657\n",
            "Train Acc at epoch 14:  0.91911334\n",
            "Eval loss at epoch 14:  0.22932625\n",
            "Eval Acc at epoch 14:  0.9202143\n",
            "Train loss at epoch 15:  0.14013863\n",
            "Train Acc at epoch 15:  0.9211928\n",
            "Eval loss at epoch 15:  0.2322501\n",
            "Eval Acc at epoch 15:  0.9221716\n",
            "Train loss at epoch 16:  0.1298524\n",
            "Train Acc at epoch 16:  0.92314386\n",
            "Eval loss at epoch 16:  0.22833768\n",
            "Eval Acc at epoch 16:  0.9241275\n",
            "Train loss at epoch 17:  0.123511076\n",
            "Train Acc at epoch 17:  0.9250228\n",
            "Eval loss at epoch 17:  0.22830223\n",
            "Eval Acc at epoch 17:  0.92593855\n",
            "Train loss at epoch 18:  0.119667634\n",
            "Train Acc at epoch 18:  0.9267646\n",
            "Eval loss at epoch 18:  0.2303022\n",
            "Eval Acc at epoch 18:  0.92759764\n",
            "Train loss at epoch 19:  0.11167824\n",
            "Train Acc at epoch 19:  0.9283883\n",
            "Eval loss at epoch 19:  0.22526133\n",
            "Eval Acc at epoch 19:  0.92921853\n",
            "Train loss at epoch 20:  0.10356696\n",
            "Train Acc at epoch 20:  0.9300269\n",
            "Eval loss at epoch 20:  0.22427256\n",
            "Eval Acc at epoch 20:  0.9308514\n"
          ]
        }
      ],
      "source": [
        "# Train and Test model\n",
        "\n",
        "acc_test = tf.keras.metrics.Mean('test_acc')\n",
        "\n",
        "seeds = np.random.randint(12,45,3)\n",
        "test_accuracy = []\n",
        "\n",
        "for i in seeds:\n",
        "  # Instantiate model. This doesn't initialize the variables yet.\n",
        "  model = ImageRecognitionCNN(num_classes=10, device=device, \n",
        "                                checkpoint_directory=checkpoint_directory)\n",
        "  print('Trial on random seed:',i)\n",
        "  model.fit_fc(train_dataset, val_dataset, optimizer, num_epochs=20, \n",
        "            early_stopping_rounds=2, verbose=1, train_from_scratch=True)\n",
        "  \n",
        "  # Compute the loss on the eval data after one epoch\n",
        "  for step, (images, target) in enumerate(test_dataset):\n",
        "    loss = model.loss_fn(images, target, False)\n",
        "    accuracy = model.compute_accuracy_2(images,target)\n",
        "    acc_test(accuracy)\n",
        "    test_accuracy.append(acc_test.result().numpy())\n",
        "\n",
        "    acc_test.reset_states()\n",
        "\n",
        "  \n",
        "  # test_mean = np.mean(test_accuracy)\n",
        "  # test_var = np.var(test_accuracy)\n",
        "\n",
        "  # print(f\"the mean of 3 runs is {test_mean}, and the variance is {test_var}\")\n",
        "  # plt.boxplot(test_accuracy)\n",
        "  # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "58JU-73ZfVWg"
      },
      "outputs": [],
      "source": [
        "test_mean = np.mean(test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6vlE0A9pfVUh",
        "outputId": "7e1fac82-46cc-4ca1-8a19-9b190775184f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9246163"
            ]
          },
          "execution_count": 121,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "i_0o0renrrfE",
        "outputId": "4716ec33-9ad2-4d97-f35c-78495281b1dc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "loss_train = model.history['train_loss']\n",
        "loss_val = model.history['eval_loss']\n",
        "epochs = range(len(model.history['eval_loss']))\n",
        "plt.plot(epochs, loss_train, 'g', label='train_loss')\n",
        "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0-SgDjkrFkd"
      },
      "source": [
        "##Batch norm after RELU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RvT6P1l_fVSk"
      },
      "outputs": [],
      "source": [
        "class ImageRecognitionCNN(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, num_classes, device='cpu:0', checkpoint_directory=None):\n",
        "        ''' Define the parameterized layers used during forward-pass, the device\n",
        "            where you would like to run the computation (GPU, TPU, CPU) on and the checkpoint\n",
        "            directory.\n",
        "            \n",
        "            Args:\n",
        "                num_classes: the number of labels in the network.\n",
        "                device: string, 'cpu:n' or 'gpu:n' (n can vary). Default, 'cpu:0'.\n",
        "                checkpoint_directory: the directory where you would like to save or \n",
        "                                      restore a model.\n",
        "        ''' \n",
        "        super(ImageRecognitionCNN, self).__init__()\n",
        "        \n",
        "        # Initialize layers\n",
        "        self.conv1 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\n",
        "        self.conv2 = tf.keras.layers.Conv2D(64, 3,padding='same', activation=None)\n",
        "        self.pool1 = tf.keras.layers.MaxPool2D()\n",
        "        self.conv3 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\n",
        "        self.conv4 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\n",
        "        # self.pool2 = tf.keras.layers.MaxPool2D()\n",
        "        # self.conv5 = tf.keras.layers.Conv2D(64, 3, padding='same', activation=None)\n",
        "        # self.pool2 = tf.keras.layers.MaxPool2D()\n",
        "        # self.conv6 = tf.keras.layers.Conv2D(64, 3, 2, padding='same', activation=None)\n",
        "        # self.conv7 = tf.keras.layers.Conv2D(64, 1, padding='same', activation=None)\n",
        "        self.conv8 = tf.keras.layers.Conv2D(num_classes, 1, padding='same', activation=None)\n",
        "        self.BatchNorm=BatchNorm(64)\n",
        "        \n",
        "        # Define the device \n",
        "        self.device = device\n",
        "        \n",
        "        # Define the checkpoint directory\n",
        "        self.checkpoint_directory = checkpoint_directory\n",
        "        self.acc = tf.keras.metrics.Accuracy()\n",
        "\n",
        "\n",
        "    def predict(self, images, training=True): #by default training is true\n",
        "        \"\"\" Predicts the probability of each class, based on the input sample.\n",
        "            \n",
        "            Args:\n",
        "                images: 4D tensor. Either an image or a batch of images.\n",
        "                training: Boolean. Either the network is predicting in\n",
        "                          training mode or not.\n",
        "                         \n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        \n",
        "        x = self.conv1(images) # (128, 28, 28, 1)(batch,28,28,1) ->(128, 28, 28, 64)<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
        "        x=self.BatchNorm(x,training)\n",
        "\n",
        "        # print(x.shape)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv2(x)\n",
        "        # print(x.shape)\n",
        "        # BatchNorm()(x)\n",
        "\n",
        "        \n",
        "        x = tf.nn.relu(x)\n",
        "        x=self.BatchNorm(x,training)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv3(x)\n",
        "        # BatchNorm()(x)\n",
        "\n",
        "\n",
        "        \n",
        "        x = tf.nn.relu(x)\n",
        "        x=self.BatchNorm(x,training)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv4(x)\n",
        "\n",
        "        # BatchNorm()(x)\n",
        "        \n",
        "        x = tf.nn.relu(x)\n",
        "        x=self.BatchNorm(x,training)\n",
        "        x = self.pool1(x)\n",
        "        x = self.conv8(x)\n",
        "        #x = tf.nn.relu(x)\n",
        "        #print(x.shape)\n",
        "        x = tf.reshape(x, (-1, 1, 10))\n",
        "        #x = tf.keras.layers.Flatten(x)\n",
        "        return x\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    def loss_fn(self, images, target, training):\n",
        "        \"\"\" Defines the loss function used during \n",
        "            training.         \n",
        "        \"\"\"\n",
        "        preds = self.predict(images, training)\n",
        "        #print(preds.shape)\n",
        "        #print(target.shape)\n",
        "        loss = tf.nn.softmax_cross_entropy_with_logits(labels=target, logits=preds)\n",
        "        return loss\n",
        "\n",
        "\n",
        "    def grads_fn(self, images, target, training):\n",
        "        \"\"\" Dynamically computes the gradients of the loss value\n",
        "            with respect to the parameters of the model, in each\n",
        "            forward pass.\n",
        "        \"\"\"\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = self.loss_fn(images, target, training)\n",
        "        return tape.gradient(loss, self.variables)\n",
        "    \n",
        "    def restore_model(self):\n",
        "        \"\"\" Function to restore trained model.\n",
        "        \"\"\"\n",
        "        with tf.device(self.device):\n",
        "            # Run the model once to initialize variables\n",
        "            dummy_input = tf.constant(tf.zeros((1,48,48,1)))\n",
        "            dummy_pred = self.predict(dummy_input, training=training) #False\n",
        "            # Restore the variables of the model\n",
        "            saver = tf.Saver(self.variables)\n",
        "            saver.restore(tf.train.latest_checkpoint\n",
        "                          (self.checkpoint_directory))\n",
        "    \n",
        "    def save_model(self, global_step=0):\n",
        "        \"\"\" Function to save trained model.\n",
        "        \"\"\"\n",
        "        tf.Saver(self.variables).save(self.checkpoint_directory, \n",
        "                                       global_step=global_step)   \n",
        "    \n",
        "\n",
        "    def compute_accuracy_2(self, images, targets):\n",
        "        \"\"\" Compute the accuracy on the input data.\n",
        "        \"\"\"\n",
        "        with tf.device(self.device):\n",
        "            \n",
        "            # Predict the probability of each class\n",
        "            logits = self.predict(images, training=training)#False\n",
        "            # Select the class with the highest probability\n",
        "            \n",
        "            logits = tf.nn.softmax(logits)\n",
        "            logits = tf.reshape(logits, [-1, 10])\n",
        "            targets = tf.reshape(targets, [-1,10])\n",
        "            preds = tf.argmax(logits, axis=1)\n",
        "            goal = tf.argmax(targets, axis=1)\n",
        "            self.acc.update_state(goal, preds)\n",
        "            # Compute the accuracy\n",
        "            result = self.acc.result().numpy()\n",
        "        return result\n",
        "\n",
        "  \n",
        "    def fit_fc(self, training_data, eval_data, optimizer, num_epochs=500, \n",
        "            early_stopping_rounds=10, verbose=10, train_from_scratch=False):\n",
        "        \"\"\" Function to train the model, using the selected optimizer and\n",
        "            for the desired number of epochs. You can either train from scratch\n",
        "            or load the latest model trained. Early stopping is used in order to\n",
        "            mitigate the risk of overfitting the network.\n",
        "            \n",
        "            Args:\n",
        "                training_data: the data you would like to train the model on.\n",
        "                                Must be in the tf.data.Dataset format.\n",
        "                eval_data: the data you would like to evaluate the model on.\n",
        "                            Must be in the tf.data.Dataset format.\n",
        "                optimizer: the optimizer used during training.\n",
        "                num_epochs: the maximum number of iterations you would like to \n",
        "                            train the model.\n",
        "                early_stopping_rounds: stop training if the loss on the eval \n",
        "                                       dataset does not decrease after n epochs.\n",
        "                verbose: int. Specify how often to print the loss value of the network.\n",
        "                train_from_scratch: boolean. Whether to initialize variables of the\n",
        "                                    the last trained model or initialize them\n",
        "                                    randomly.\n",
        "        \"\"\" \n",
        "    \n",
        "        if train_from_scratch==False:\n",
        "            self.restore_model()\n",
        "        \n",
        "        # Initialize best loss. This variable will store the lowest loss on the\n",
        "        # eval dataset.\n",
        "        best_loss = 999\n",
        "        \n",
        "        # Initialize classes to update the mean loss of train and eval\n",
        "        train_loss = tf.keras.metrics.Mean('train_loss')\n",
        "        eval_loss = tf.keras.metrics.Mean('eval_loss')\n",
        "        acc_train = tf.keras.metrics.Mean('train_acc')\n",
        "        acc_val = tf.keras.metrics.Mean('val_acc')\n",
        "        \n",
        "        # Initialize dictionary to store the loss history\n",
        "        self.history = {}\n",
        "        self.history['train_loss'] = []\n",
        "        self.history['eval_loss'] = []\n",
        "        self.history['train_acc'] = []\n",
        "        self.history['val_acc'] = []\n",
        "        \n",
        "        # Begin training\n",
        "        \n",
        "        with tf.device(self.device):\n",
        "            for i in range(num_epochs):\n",
        "                # Training with gradient descent\n",
        "                #training_data_x = training_data.shuffle(buffer_size=1024).batch(128)\n",
        "                for step, (images, target) in enumerate(training_data):\n",
        "                    grads = self.grads_fn(images, target, training=training)#True\n",
        "                    optimizer.apply_gradients(zip(grads, self.variables))\n",
        "                    \n",
        "                # Compute the loss on the training data after one epoch\n",
        "                for step, (images, target) in enumerate(training_data):\n",
        "                    loss = self.loss_fn(images, target, training=training) #False\n",
        "                    accuracy = self.compute_accuracy_2(images,target)\n",
        "                    acc_train(accuracy)\n",
        "                    train_loss(loss)\n",
        "                self.history['train_loss'].append(train_loss.result().numpy())\n",
        "                self.history['train_acc'].append(acc_train.result().numpy())\n",
        "                # Reset metrics\n",
        "                train_loss.reset_states()\n",
        "                acc_train.reset_states()\n",
        "                \n",
        "                # Compute the loss on the eval data after one epoch\n",
        "                for step, (images, target) in enumerate(eval_data):\n",
        "                    loss = self.loss_fn(images, target, training=training) #False\n",
        "                    accuracy = self.compute_accuracy_2(images,target)\n",
        "                    acc_val(accuracy)\n",
        "                    eval_loss(loss)\n",
        "                self.history['eval_loss'].append(eval_loss.result().numpy())\n",
        "                self.history['val_acc'].append(acc_val.result().numpy())\n",
        "                # Reset metrics\n",
        "                eval_loss.reset_states()\n",
        "                acc_val.reset_states()\n",
        "                \n",
        "                # Print train and eval losses\n",
        "                if (i==0) | ((i+1)%verbose==0):\n",
        "                    print('Train loss at epoch %d: ' %(i+1), self.history['train_loss'][-1])\n",
        "                    print('Train Acc at epoch %d: ' %(i+1), self.history['train_acc'][-1])\n",
        "                    \n",
        "                    print('Eval loss at epoch %d: ' %(i+1), self.history['eval_loss'][-1])\n",
        "                    print('Eval Acc at epoch %d: ' %(i+1), self.history['val_acc'][-1])\n",
        "\n",
        "                # Check for early stopping\n",
        "                if self.history['eval_loss'][-1]<best_loss:\n",
        "                    best_loss = self.history['eval_loss'][-1]\n",
        "                    count = early_stopping_rounds\n",
        "                else:\n",
        "                    count -= 1\n",
        "                if count==0:\n",
        "                    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZWDRmvorak5"
      },
      "outputs": [],
      "source": [
        "# Specify the path where you want to save/restore the trained variables.\n",
        "checkpoint_directory = '/content/sample_data/checkpoint'\n",
        "\n",
        "# Use the GPU if available.\n",
        "device = 'gpu:0'\n",
        "\n",
        "# Define optimizer.\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=1e-4)\n",
        "\n",
        "# Instantiate model. This doesn't initialize the variables yet.\n",
        "model = ImageRecognitionCNN(num_classes=10, device=device, \n",
        "                              checkpoint_directory=checkpoint_directory)\n",
        "\n",
        "#model = ImageRecognitionCNN(num_classes=7, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmcyvVX0raiD",
        "outputId": "a4bd012c-5b28-4917-f605-a6e3a524da2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial on random seed: 31\n",
            "Train loss at epoch 1:  1.2230809\n",
            "Train Acc at epoch 1:  0.8063138\n",
            "Eval loss at epoch 1:  1.2255476\n",
            "Eval Acc at epoch 1:  0.8075143\n",
            "Train loss at epoch 2:  0.65839\n",
            "Train Acc at epoch 2:  0.8208721\n",
            "Eval loss at epoch 2:  0.6654389\n",
            "Eval Acc at epoch 2:  0.83127856\n",
            "Train loss at epoch 3:  0.44223884\n",
            "Train Acc at epoch 3:  0.84056425\n",
            "Eval loss at epoch 3:  0.45429483\n",
            "Eval Acc at epoch 3:  0.8483261\n",
            "Train loss at epoch 4:  0.35298556\n",
            "Train Acc at epoch 4:  0.8548719\n",
            "Eval loss at epoch 4:  0.3724994\n",
            "Eval Acc at epoch 4:  0.8603368\n",
            "Train loss at epoch 5:  0.30312565\n",
            "Train Acc at epoch 5:  0.8650367\n",
            "Eval loss at epoch 5:  0.32956183\n",
            "Eval Acc at epoch 5:  0.8692994\n",
            "Train loss at epoch 6:  0.27012184\n",
            "Train Acc at epoch 6:  0.8730123\n",
            "Eval loss at epoch 6:  0.30338943\n",
            "Eval Acc at epoch 6:  0.8765162\n",
            "Train loss at epoch 7:  0.25107968\n",
            "Train Acc at epoch 7:  0.8792588\n",
            "Eval loss at epoch 7:  0.2890604\n",
            "Eval Acc at epoch 7:  0.88202834\n",
            "Train loss at epoch 8:  0.2312391\n",
            "Train Acc at epoch 8:  0.8844978\n",
            "Eval loss at epoch 8:  0.27816838\n",
            "Eval Acc at epoch 8:  0.8869372\n",
            "Train loss at epoch 9:  0.21110772\n",
            "Train Acc at epoch 9:  0.8891095\n",
            "Eval loss at epoch 9:  0.26437852\n",
            "Eval Acc at epoch 9:  0.8913204\n",
            "Train loss at epoch 10:  0.1977771\n",
            "Train Acc at epoch 10:  0.8932447\n",
            "Eval loss at epoch 10:  0.2590902\n",
            "Eval Acc at epoch 10:  0.8951807\n",
            "Train loss at epoch 11:  0.18729123\n",
            "Train Acc at epoch 11:  0.8968685\n",
            "Eval loss at epoch 11:  0.25432685\n",
            "Eval Acc at epoch 11:  0.89858544\n",
            "Train loss at epoch 12:  0.1763326\n",
            "Train Acc at epoch 12:  0.90016997\n",
            "Eval loss at epoch 12:  0.24934265\n",
            "Eval Acc at epoch 12:  0.9017767\n",
            "Train loss at epoch 13:  0.16647391\n",
            "Train Acc at epoch 13:  0.90319675\n",
            "Eval loss at epoch 13:  0.24764682\n",
            "Eval Acc at epoch 13:  0.9046541\n",
            "Train loss at epoch 14:  0.155819\n",
            "Train Acc at epoch 14:  0.90598005\n",
            "Eval loss at epoch 14:  0.24751665\n",
            "Eval Acc at epoch 14:  0.9073412\n",
            "Train loss at epoch 15:  0.15179381\n",
            "Train Acc at epoch 15:  0.9085036\n",
            "Eval loss at epoch 15:  0.25189823\n",
            "Eval Acc at epoch 15:  0.90970206\n",
            "Train loss at epoch 16:  0.14073484\n",
            "Train Acc at epoch 16:  0.9108032\n",
            "Eval loss at epoch 16:  0.24718101\n",
            "Eval Acc at epoch 16:  0.91200346\n",
            "Train loss at epoch 17:  0.13259827\n",
            "Train Acc at epoch 17:  0.91307664\n",
            "Eval loss at epoch 17:  0.24898228\n",
            "Eval Acc at epoch 17:  0.91421115\n",
            "Train loss at epoch 18:  0.13322827\n",
            "Train Acc at epoch 18:  0.9151347\n",
            "Eval loss at epoch 18:  0.25432572\n",
            "Eval Acc at epoch 18:  0.9161038\n",
            "Trial on random seed: 24\n",
            "Train loss at epoch 1:  0.5548525\n",
            "Train Acc at epoch 1:  0.8722676\n",
            "Eval loss at epoch 1:  0.56976277\n",
            "Eval Acc at epoch 1:  0.8725455\n",
            "Train loss at epoch 2:  0.3578927\n",
            "Train Acc at epoch 2:  0.8789539\n",
            "Eval loss at epoch 2:  0.3818407\n",
            "Eval Acc at epoch 2:  0.88434976\n",
            "Train loss at epoch 3:  0.2935931\n",
            "Train Acc at epoch 3:  0.88834804\n",
            "Eval loss at epoch 3:  0.32542452\n",
            "Eval Acc at epoch 3:  0.89197886\n",
            "Train loss at epoch 4:  0.25192016\n",
            "Train Acc at epoch 4:  0.89516723\n",
            "Eval loss at epoch 4:  0.29235762\n",
            "Eval Acc at epoch 4:  0.8981973\n",
            "Train loss at epoch 5:  0.23289412\n",
            "Train Acc at epoch 5:  0.90047073\n",
            "Eval loss at epoch 5:  0.2815073\n",
            "Eval Acc at epoch 5:  0.9025908\n",
            "Train loss at epoch 6:  0.21218735\n",
            "Train Acc at epoch 6:  0.90452033\n",
            "Eval loss at epoch 6:  0.26790646\n",
            "Eval Acc at epoch 6:  0.9064583\n",
            "Train loss at epoch 7:  0.19671528\n",
            "Train Acc at epoch 7:  0.9082404\n",
            "Eval loss at epoch 7:  0.26087052\n",
            "Eval Acc at epoch 7:  0.9100007\n",
            "Train loss at epoch 8:  0.18245274\n",
            "Train Acc at epoch 8:  0.9114738\n",
            "Eval loss at epoch 8:  0.25593966\n",
            "Eval Acc at epoch 8:  0.91301274\n",
            "Train loss at epoch 9:  0.16913877\n",
            "Train Acc at epoch 9:  0.9144199\n",
            "Eval loss at epoch 9:  0.24950036\n",
            "Eval Acc at epoch 9:  0.91588557\n",
            "Train loss at epoch 10:  0.15625922\n",
            "Train Acc at epoch 10:  0.9171993\n",
            "Eval loss at epoch 10:  0.2444344\n",
            "Eval Acc at epoch 10:  0.91860914\n",
            "Train loss at epoch 11:  0.15192963\n",
            "Train Acc at epoch 11:  0.91971093\n",
            "Eval loss at epoch 11:  0.24753684\n",
            "Eval Acc at epoch 11:  0.9208739\n",
            "Train loss at epoch 12:  0.14063124\n",
            "Train Acc at epoch 12:  0.92194957\n",
            "Eval loss at epoch 12:  0.24488989\n",
            "Eval Acc at epoch 12:  0.9230544\n",
            "Trial on random seed: 36\n",
            "Train loss at epoch 1:  0.57591224\n",
            "Train Acc at epoch 1:  0.860719\n",
            "Eval loss at epoch 1:  0.58659524\n",
            "Eval Acc at epoch 1:  0.86239016\n",
            "Train loss at epoch 2:  0.36913243\n",
            "Train Acc at epoch 2:  0.87025785\n",
            "Eval loss at epoch 2:  0.388797\n",
            "Eval Acc at epoch 2:  0.8770562\n",
            "Train loss at epoch 3:  0.29337484\n",
            "Train Acc at epoch 3:  0.8826339\n",
            "Eval loss at epoch 3:  0.32181847\n",
            "Eval Acc at epoch 3:  0.8876478\n",
            "Train loss at epoch 4:  0.25794291\n",
            "Train Acc at epoch 4:  0.89151454\n",
            "Eval loss at epoch 4:  0.29411957\n",
            "Eval Acc at epoch 4:  0.8950093\n",
            "Train loss at epoch 5:  0.23372015\n",
            "Train Acc at epoch 5:  0.89789534\n",
            "Eval loss at epoch 5:  0.27723458\n",
            "Eval Acc at epoch 5:  0.9005815\n",
            "Train loss at epoch 6:  0.21176583\n",
            "Train Acc at epoch 6:  0.90286577\n",
            "Eval loss at epoch 6:  0.2629907\n",
            "Eval Acc at epoch 6:  0.9051258\n",
            "Train loss at epoch 7:  0.19721805\n",
            "Train Acc at epoch 7:  0.9069994\n",
            "Eval loss at epoch 7:  0.25656703\n",
            "Eval Acc at epoch 7:  0.9088753\n",
            "Train loss at epoch 8:  0.1839387\n",
            "Train Acc at epoch 8:  0.91051084\n",
            "Eval loss at epoch 8:  0.2532834\n",
            "Eval Acc at epoch 8:  0.91216964\n",
            "Train loss at epoch 9:  0.16919826\n",
            "Train Acc at epoch 9:  0.91368896\n",
            "Eval loss at epoch 9:  0.24700797\n",
            "Eval Acc at epoch 9:  0.91525304\n",
            "Train loss at epoch 10:  0.15823583\n",
            "Train Acc at epoch 10:  0.9165773\n",
            "Eval loss at epoch 10:  0.24687022\n",
            "Eval Acc at epoch 10:  0.91799307\n",
            "Train loss at epoch 11:  0.149671\n",
            "Train Acc at epoch 11:  0.91921115\n",
            "Eval loss at epoch 11:  0.24853599\n",
            "Eval Acc at epoch 11:  0.9204872\n",
            "Train loss at epoch 12:  0.14793243\n",
            "Train Acc at epoch 12:  0.92143244\n",
            "Eval loss at epoch 12:  0.2530837\n",
            "Eval Acc at epoch 12:  0.9224672\n"
          ]
        }
      ],
      "source": [
        "# Train and Test model\n",
        "\n",
        "acc_test = tf.keras.metrics.Mean('test_acc')\n",
        "\n",
        "seeds = np.random.randint(12,45,3)\n",
        "test_accuracy = []\n",
        "\n",
        "for i in seeds:\n",
        "  # Instantiate model. This doesn't initialize the variables yet.\n",
        "  model = ImageRecognitionCNN(num_classes=10, device=device, \n",
        "                                checkpoint_directory=checkpoint_directory)\n",
        "  print('Trial on random seed:',i)\n",
        "  model.fit_fc(train_dataset, val_dataset, optimizer, num_epochs=20, \n",
        "            early_stopping_rounds=2, verbose=1, train_from_scratch=True)\n",
        "  \n",
        "  # Compute the loss on the eval data after one epoch\n",
        "  for step, (images, target) in enumerate(test_dataset):\n",
        "    loss = model.loss_fn(images, target, False)\n",
        "    accuracy = model.compute_accuracy_2(images,target)\n",
        "    acc_test(accuracy)\n",
        "    test_accuracy.append(acc_test.result().numpy())\n",
        "\n",
        "    acc_test.reset_states()\n",
        "\n",
        "  \n",
        "  # test_mean = np.mean(test_accuracy)\n",
        "  # test_var = np.var(test_accuracy)\n",
        "\n",
        "  # print(f\"the mean of 3 runs is {test_mean}, and the variance is {test_var}\")\n",
        "  # plt.boxplot(test_accuracy)\n",
        "  # plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1CxMEKOraZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae94a445-7769-4f92-b2bf-9e8aec90d3d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.92041403"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "test_mean = np.mean(test_accuracy)\n",
        "test_mean"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_train = model.history['train_loss']\n",
        "loss_val = model.history['eval_loss']\n",
        "epochs = range(len(model.history['eval_loss']))\n",
        "plt.plot(epochs, loss_train, 'g', label='train_loss')\n",
        "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
        "plt.title('Training and Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "NkkyKRCMCBQP",
        "outputId": "e5c060b3-7429-4282-9036-8ffe36375ec3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxVzxy7j7D0o"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "IST597_Building_CNN_batchNorm.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}